DATASETS:
  # Source - haptik / dialoglue
  DATASET_SOURCE: "haptik"
  # For Haptik - curekart / powerplay11 / sofmattress
  # For Dialogue - banking / clinc / hwu
  DATASET_NAME: "curekart"
  OOS_CLASS_NAME: "NO_NODES_DETECTED"
  # Subsets of train data to use. haptik - "train"/"subset_train", dialoglue - "train"/"train_5"/"train_10"
  DATA_SUBSET: "train"
  N_LABELS: 28

# Training parameters only for BERT based models
TRAINING:
  # Model - type - CROSS_ENCODER / BI_ENCODER / CLASSIFIER / SBERT_CROSS_ENCODER
  MODEL_TYPE : "BI_ENCODER"
  NUM_ITERATIONS : 10000
  TRAIN_OUTPUT_DIR: "./models/"
  # Specify the model like "sentence-transformers/all-MiniLM-L6-v2" or "bert-base-uncased" /"cross-encoder/stsb-distilroberta-base"
  MODEL_NAME : "sentence-transformers/all-MiniLM-L6-v2"
  TOKENIZER_NAME: "sentence-transformers/all-MiniLM-L6-v2"
  # Specify model layer to unfreeze - 11,5 etc
  LAYERS_TO_UNFREEZE : [5]
  # Specify a loss metric for Sentence Bert Bi-Encoder models - CosineSimilarityLoss / ContrastiveLoss
  LOSS_METRIC : "ContrastiveLoss"
  BATCH_SIZE : 16
  LEARNING_RATE: 2e-5
  # Specify scheduler - "WarmupLinear" for SentenceBert / "linear" for Bert
  SCHEDULER: 'WarmupLinear'
  VALIDATION_SPLIT: 0.2

# Evaluation for all methods including pre-trained models, BM25, Glove, Fasttext, finedtuned models etc
EVALUATION:
  # Evaluation methods - BERT_EMBEDDINGS / BERT_CROSS_ENCODER / CLASSIFIER / SBERT_CROSS_ENCODER / BM25 / GLOVE / FASTTEXT / TFIDF_WORD_EMBEDDINGS / TFIDF_CHAR_EMBEDDINGS / CV_EMBEDDINGS
  EVALUATION_METHOD : "BERT_EMBEDDINGS"
  # Model name for evaluation - # Specify a model name which is implemented via Huggingface - "bert-base-uncased" / "models/convbert" (DialoGLUE convbert model) / "sentence-transformers/all-MiniLM-L6-v2"
  MODEL_NAME : "sentence-transformers/all-MiniLM-L6-v2"
  TOKENIZER_NAME: "sentence-transformers/all-MiniLM-L6-v2"
  BATCH_SIZE : 16
  # Glove & Fastext model paths
  FASTTEXT_MODEL_PATH: "models/fasttext_ecom_model_2.bin"
  GLOVE_MODEL_PATH: "models/glove.6B/glove.6B.300d.txt"
  # Set True/False for the evaluation metrics
  CHECK_SUCCESS_RATE: True
  CHECK_PRECISION : True
  CHECK_MAP: True
  CHECK_NDCG: True
  CHECK_MRR: True
  CHECK_F1_MACRO: True
  CHECK_F1_MICRO: True
  CHECK_F1_WEIGHTED: True
  CHECK_OOS_ACCURACY : True
  OOS_THRESHOLD : [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]
  # Specify k values less than 10
  K_VAL : [1,2,3,5]


INFERENCE:
  CLIENT_SOURCE : "haptik"
  CLIENT_NAMES : ["curekart", "powerplay11"]
  INFERENCE_FILE_PATH: "data/inference.txt"
  MODEL_DIR: "models"
  MODEL_PATH: "sentence-transformers/all-MiniLM-L6-v2"
  EMBEDDING_FILE_NAME: "embeddings.npy"
  TEXTS_FILE_NAME: "texts.npy"
  LABELS_FILE_NAME: "labels.npy"
  LAYERS_TO_LOAD: [5]
